import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

#read dataframe with hourly granularity
db_1=pd.read_csv( '/Users/antonio/Desktop/tesi/crypto/ETH/ETH_hour.csv')
if 'date' in db_1.columns :
  del db_1['date']

#shift price series of 1 entry
db_1['close_h_1']=db_1['close'].shift(-1)

print(db_1.close_h_1)
Social_missing = db_1.isna()
Social_num_missing = Social_missing.sum()
Percentage_missing_social= Social_num_missing / len(db_1)

median_1=db_1.median()
Q1_1 = db_1.quantile(0.25)
Q3_1 = db_1.quantile(0.75)
IQR_1 = Q3_1 - Q1_1
print(IQR_1)
outliers=(db_1 < (Q1_1 - 1.5 * IQR_1)) |(db_1> (Q3_1 + 1.5 * IQR_1))
db_1[outliers] = np.nan
db_1.fillna(median_1, inplace=True)

# heat correlation matrix for social dataframe
def heatMap(df):
    #Create Correlation df
    corr = df.corr()
    #Plot figsize
    fig, ax = plt.subplots(figsize=(16, 10))
    #Generate Color Map
    colormap = sns.diverging_palette(220, 10, as_cmap=True)
    #Generate Heat Map, allow annotations and place floats in map
    sns.heatmap(corr, cmap=colormap, annot=True, fmt=".1f")
    #Apply xticks
    plt.xticks(range(len(corr.columns)), corr.columns);
    #Apply yticks
    plt.yticks(range(len(corr.columns)), corr.columns)
    #show plot
    plt.show()
    plt.savefig('Socialmap.png')
    

image=heatMap(db_1)

# standardization of variable
s = StandardScaler()
close_1= db_1[['close_h_1','fb_likes']].loc[4000:6000]
scaled=s.fit_transform(close_1)
pd.DataFrame(scaled, columns=['close_h_1_ETH', 'fb_likes_ETH']).plot()
plt.savefig('Socilaplot.png')

#read dataframe with daily granularity
db_2=pd.read_csv('/Users/antonio/Desktop/tesi/crypto/LTC/ltc_day.csv')
if 'date' in db_2.columns :
  del db_2['date']

db_2.drop(db_2.columns[[-2]], axis=1, inplace=True)
db_2.drop(db_2.tail(1).index,inplace=True)
db_2['close'] = db_2['close'].str.replace(',', '').astype(float)
db_2['open'] = db_2['open'].str.replace(',', '').astype(float)
db_2['high'] = db_2['high'].str.replace(',', '').astype(float)
db_2['low'] = db_2['low'].str.replace(',', '').astype(float)

db_2['close_d_1']=db_2['close'].shift(-1)

median_2=db_2.median()
Q1_2 = db_2.quantile(0.25)
Q3_2 = db_2.quantile(0.75)
IQR_2 = Q3_2 - Q1_2
print(IQR_2)
outliers_2=(db_2 < (Q1_2 - 1.5 * IQR_2)) |(db_2> (Q3_2 + 1.5 * IQR_2))
db_2[outliers_2] = np.nan
db_2.fillna(median_2, inplace=True)

#heta correlation matrix for blockchain dataframe
def heatMap(df):
    #Create Correlation df
    corr = df.corr()
    #Plot figsize
    fig, ax = plt.subplots(figsize=(16 ,10))
    #Generate Color Map
    colormap = sns.diverging_palette(220, 10, as_cmap=True)
    #Generate Heat Map, allow annotations and place floats in map
    sns.heatmap(corr, cmap=colormap, annot=True, fmt=".1f")
    #Apply xticks
    plt.xticks(range(len(corr.columns)), corr.columns);
    #Apply yticks
    plt.yticks(range(len(corr.columns)), corr.columns)
    #show plot
    plt.show()
    plt.savefig('Blockcha')
    

image=heatMap(db_2)

# standardization of variable
s = StandardScaler()
close_2= db_2[['close_d_1','TxTfrValMedUSD']].loc[800:1500]
scaled=s.fit_transform(close_2)
     
pd.DataFrame(scaled, columns=['close_h_1_ETH', 'TxTfrValMedUSD_ETH']).plot()
plt.savefig('Blockchain.png')

